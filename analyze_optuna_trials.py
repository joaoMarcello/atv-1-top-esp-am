"""
Script para analisar os melhores trials do Optuna
Extrai mÃ©tricas globais e por classe dos top 5 trials
"""

import argparse
import pickle
import optuna
from pathlib import Path
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # Backend sem interface grÃ¡fica
import os


def parse_args():
    """Parse argumentos de linha de comando"""
    parser = argparse.ArgumentParser(
        description='Analisa os melhores trials do Optuna e salva mÃ©tricas detalhadas',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    parser.add_argument(
        '--study_path',
        type=str,
        required=True,
        help='Caminho para o arquivo pickle do study do Optuna (ex: best_model_data/optuna_study.pkl)'
    )
    
    parser.add_argument(
        '--output',
        type=str,
        default='top_trials_analysis.txt',
        help='Arquivo de saÃ­da para salvar a anÃ¡lise'
    )
    
    parser.add_argument(
        '--top_n',
        type=int,
        default=5,
        help='NÃºmero de melhores trials para analisar'
    )
    
    parser.add_argument(
        '--include_pruned',
        action='store_true',
        help='Se ativado, inclui trials pruned na anÃ¡lise (baseado no F1 do Fold 1)'
    )
    
    parser.add_argument(
        '--generate_plots',
        action='store_true',
        help='Se ativado, gera grÃ¡ficos de mÃ©tricas por Ã©poca para cada trial'
    )
    
    parser.add_argument(
        '--plots_dir',
        type=str,
        default='plots',
        help='DiretÃ³rio para salvar os grÃ¡ficos'
    )
    
    return parser.parse_args()


def load_optuna_study(study_path):
    """Carrega o study do Optuna"""
    try:
        with open(study_path, 'rb') as f:
            study = pickle.load(f)
        print(f"âœ… Study carregado com sucesso: {study_path}")
        print(f"   Total de trials: {len(study.trials)}")
        return study
    except FileNotFoundError:
        print(f"âŒ Erro: Arquivo nÃ£o encontrado: {study_path}")
        return None
    except Exception as e:
        print(f"âŒ Erro ao carregar study: {e}")
        return None


def get_trial_metrics_summary(trial):
    """Extrai resumo das mÃ©tricas de um trial"""
    summary = {
        'trial_number': trial.number,
        'state': trial.state.name,
        'value': None,
        'params': trial.params,
        'fold_metrics': []
    }
    
    # Verificar se Ã© trial completado
    if trial.state == optuna.trial.TrialState.COMPLETE:
        summary['value'] = trial.value
        # Aqui nÃ£o temos acesso direto aos fold metrics, apenas ao valor final
        # mas podemos buscar nos user_attrs se foram salvos
        if 'fold_results' in trial.user_attrs:
            summary['fold_metrics'] = trial.user_attrs['fold_results']
    
    # Para trials pruned, tentar pegar mÃ©tricas do primeiro fold
    elif trial.state == optuna.trial.TrialState.PRUNED:
        if 'first_fold_val_metrics' in trial.user_attrs:
            summary['value'] = trial.user_attrs['first_fold_val_metrics'].get('f1_score', 0.0)
            summary['pruned_reason'] = trial.user_attrs.get('pruned_reason', 'unknown')
            fold_metric = {
                'fold': 1,
                'val_metrics': trial.user_attrs.get('first_fold_val_metrics', {}),
                'train_metrics': trial.user_attrs.get('first_fold_train_metrics', {}),
                'best_epoch': trial.user_attrs.get('first_fold_best_epoch', 'N/A')
            }
            # Incluir histÃ³rico se disponÃ­vel
            if 'first_fold_history' in trial.user_attrs:
                fold_metric['history'] = trial.user_attrs['first_fold_history']
            summary['fold_metrics'] = [fold_metric]
    
    return summary


def format_metrics_per_class(metrics, indent='    '):
    """Formata mÃ©tricas por classe em tabela ASCII"""
    lines = []
    
    # Verificar se hÃ¡ mÃ©tricas por classe
    has_metrics = any(key in metrics for key in ['f1_per_class', 'sensitivities_per_class', 
                                                   'specificities_per_class', 'kappa_per_class'])
    
    if not has_metrics:
        return ""
    
    # Determinar nÃºmero de classes
    num_classes = 5  # PadrÃ£o
    if 'f1_per_class' in metrics:
        num_classes = len(metrics['f1_per_class'])
    elif 'sensitivities_per_class' in metrics:
        num_classes = len(metrics['sensitivities_per_class'])
    
    # CabeÃ§alho da tabela
    lines.append(f"{indent}â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    lines.append(f"{indent}â”‚ Classeâ”‚  F1-Score  â”‚ Sensibilidadeâ”‚ Especificidade â”‚   Kappa    â”‚")
    lines.append(f"{indent}â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    
    # Dados por classe
    for i in range(num_classes):
        f1 = metrics.get('f1_per_class', [0.0]*num_classes)[i]
        sens = metrics.get('sensitivities_per_class', [0.0]*num_classes)[i]
        spec = metrics.get('specificities_per_class', [0.0]*num_classes)[i]
        kappa = metrics.get('kappa_per_class', [0.0]*num_classes)[i]
        
        lines.append(f"{indent}â”‚   {i}   â”‚   {f1:6.4f}   â”‚    {sens:6.4f}    â”‚     {spec:6.4f}     â”‚  {kappa:6.4f}  â”‚")
    
    # RodapÃ© da tabela
    lines.append(f"{indent}â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    return '\n'.join(lines)


def format_global_metrics(metrics, indent='    '):
    """Formata mÃ©tricas globais em tabela ASCII"""
    lines = []
    
    # Tabela de mÃ©tricas globais
    lines.append(f"{indent}â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    lines.append(f"{indent}â”‚      MÃ©trica        â”‚  Valor   â”‚")
    lines.append(f"{indent}â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    
    if 'f1_score' in metrics:
        lines.append(f"{indent}â”‚ F1-score (macro)    â”‚  {metrics['f1_score']:6.4f}  â”‚")
    if 'accuracy' in metrics:
        lines.append(f"{indent}â”‚ Accuracy            â”‚  {metrics['accuracy']*100:5.2f}%  â”‚")
    if 'kappa' in metrics:
        lines.append(f"{indent}â”‚ Kappa               â”‚  {metrics['kappa']:6.4f}  â”‚")
    if 'sensitivity' in metrics:
        lines.append(f"{indent}â”‚ Sensitivity (macro) â”‚  {metrics['sensitivity']:6.4f}  â”‚")
    if 'specificity' in metrics:
        lines.append(f"{indent}â”‚ Specificity (macro) â”‚  {metrics['specificity']:6.4f}  â”‚")
    if 'loss' in metrics:
        lines.append(f"{indent}â”‚ Loss                â”‚  {metrics['loss']:6.4f}  â”‚")
    
    lines.append(f"{indent}â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    return '\n'.join(lines)


def generate_trial_plots(trial_summary, rank, output_dir):
    """
    Gera grÃ¡ficos de mÃ©tricas por Ã©poca para um trial
    
    Args:
        trial_summary: DicionÃ¡rio com informaÃ§Ãµes do trial
        rank: PosiÃ§Ã£o do trial no ranking
        output_dir: DiretÃ³rio onde salvar os grÃ¡ficos
    """
    # Verificar se hÃ¡ dados de histÃ³rico
    if not trial_summary['fold_metrics']:
        print(f"   âš ï¸ Trial {trial_summary['trial_number']}: Sem dados de histÃ³rico para plotar")
        return None
    
    # Iterar pelos folds (geralmente serÃ¡ apenas 1 para trials pruned)
    for fold_idx, fold_data in enumerate(trial_summary['fold_metrics'], 1):
        if not isinstance(fold_data, dict) or 'history' not in fold_data:
            print(f"   âš ï¸ Trial {trial_summary['trial_number']} Fold {fold_idx}: Sem histÃ³rico disponÃ­vel")
            continue
        
        history = fold_data['history']
        
        # Verificar se hÃ¡ dados suficientes
        required_keys = ['epochs', 'train_loss', 'val_loss', 'train_f1', 'val_f1', 
                        'train_sensitivity', 'val_sensitivity', 'train_specificity', 'val_specificity']
        
        if not all(key in history for key in required_keys):
            print(f"   âš ï¸ Trial {trial_summary['trial_number']} Fold {fold_idx}: Dados incompletos")
            continue
        
        epochs = history['epochs']
        if not epochs or len(epochs) == 0:
            print(f"   âš ï¸ Trial {trial_summary['trial_number']} Fold {fold_idx}: Nenhuma Ã©poca registrada")
            continue
        
        # Criar figura com 4 subplots (2x2)
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle(f'Trial {trial_summary["trial_number"]} (Rank #{rank}) - Fold {fold_idx}\n'
                    f'Head: {trial_summary["params"].get("head_type", "N/A")} | '
                    f'Block: {trial_summary["params"].get("block_type", "N/A")} | '
                    f'Best Epoch: {fold_data.get("best_epoch", "N/A")}', 
                    fontsize=14, fontweight='bold')
        
        # 1. Loss
        ax1 = axes[0, 0]
        ax1.plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)
        ax1.plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)
        if 'best_epoch' in fold_data and fold_data['best_epoch'] != 'N/A':
            ax1.axvline(x=fold_data['best_epoch'], color='g', linestyle='--', 
                       label=f'Best Epoch ({fold_data["best_epoch"]})', linewidth=1.5)
        ax1.set_xlabel('Ã‰poca', fontsize=11)
        ax1.set_ylabel('Loss', fontsize=11)
        ax1.set_title('Loss por Ã‰poca', fontsize=12, fontweight='bold')
        ax1.legend(loc='best')
        ax1.grid(True, alpha=0.3)
        
        # 2. F1-Score
        ax2 = axes[0, 1]
        ax2.plot(epochs, history['train_f1'], 'b-', label='Train F1', linewidth=2)
        ax2.plot(epochs, history['val_f1'], 'r-', label='Val F1', linewidth=2)
        if 'best_epoch' in fold_data and fold_data['best_epoch'] != 'N/A':
            ax2.axvline(x=fold_data['best_epoch'], color='g', linestyle='--', 
                       label=f'Best Epoch ({fold_data["best_epoch"]})', linewidth=1.5)
        ax2.set_xlabel('Ã‰poca', fontsize=11)
        ax2.set_ylabel('F1-Score', fontsize=11)
        ax2.set_title('F1-Score por Ã‰poca', fontsize=12, fontweight='bold')
        ax2.legend(loc='best')
        ax2.grid(True, alpha=0.3)
        ax2.set_ylim([0, 1])
        
        # 3. Sensitivity
        ax3 = axes[1, 0]
        ax3.plot(epochs, history['train_sensitivity'], 'b-', label='Train Sensitivity', linewidth=2)
        ax3.plot(epochs, history['val_sensitivity'], 'r-', label='Val Sensitivity', linewidth=2)
        if 'best_epoch' in fold_data and fold_data['best_epoch'] != 'N/A':
            ax3.axvline(x=fold_data['best_epoch'], color='g', linestyle='--', 
                       label=f'Best Epoch ({fold_data["best_epoch"]})', linewidth=1.5)
        ax3.set_xlabel('Ã‰poca', fontsize=11)
        ax3.set_ylabel('Sensitivity', fontsize=11)
        ax3.set_title('Sensitivity por Ã‰poca', fontsize=12, fontweight='bold')
        ax3.legend(loc='best')
        ax3.grid(True, alpha=0.3)
        ax3.set_ylim([0, 1])
        
        # 4. Specificity
        ax4 = axes[1, 1]
        ax4.plot(epochs, history['train_specificity'], 'b-', label='Train Specificity', linewidth=2)
        ax4.plot(epochs, history['val_specificity'], 'r-', label='Val Specificity', linewidth=2)
        if 'best_epoch' in fold_data and fold_data['best_epoch'] != 'N/A':
            ax4.axvline(x=fold_data['best_epoch'], color='g', linestyle='--', 
                       label=f'Best Epoch ({fold_data["best_epoch"]})', linewidth=1.5)
        ax4.set_xlabel('Ã‰poca', fontsize=11)
        ax4.set_ylabel('Specificity', fontsize=11)
        ax4.set_title('Specificity por Ã‰poca', fontsize=12, fontweight='bold')
        ax4.legend(loc='best')
        ax4.grid(True, alpha=0.3)
        ax4.set_ylim([0, 1])
        
        # Ajustar layout
        plt.tight_layout()
        
        # Salvar figura
        filename = f"trial_{trial_summary['trial_number']}_rank_{rank}_fold_{fold_idx}.png"
        filepath = os.path.join(output_dir, filename)
        plt.savefig(filepath, dpi=150, bbox_inches='tight')
        plt.close(fig)
        
        print(f"   âœ… GrÃ¡fico salvo: {filename}")
        
        return filepath
    
    return None


def analyze_and_save(study, output_path, top_n=5, include_pruned=False, generate_plots=False, plots_dir='plots'):
    """Analisa os melhores trials e salva em arquivo"""
    
    # Separar trials por estado
    completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]
    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]
    
    print(f"\nğŸ“Š AnÃ¡lise do Study:")
    print(f"   Trials completados: {len(completed_trials)}")
    print(f"   Trials pruned: {len(pruned_trials)}")
    
    # Selecionar trials para anÃ¡lise
    if include_pruned and len(completed_trials) == 0:
        print(f"\nâš ï¸ Nenhum trial completado! Analisando trials pruned...")
        # Ordenar trials pruned por F1 do Fold 1
        trials_to_analyze = []
        for trial in pruned_trials:
            if 'first_fold_val_metrics' in trial.user_attrs:
                f1 = trial.user_attrs['first_fold_val_metrics'].get('f1_score', 0.0)
                trials_to_analyze.append((trial, f1))
        
        trials_to_analyze.sort(key=lambda x: x[1], reverse=True)
        top_trials = [t[0] for t in trials_to_analyze[:top_n]]
        analysis_type = "PRUNED"
    else:
        # Pegar os melhores trials completados
        try:
            top_trials = study.best_trials[:top_n]
            analysis_type = "COMPLETADOS"
        except:
            # Se best_trials falhar, ordenar manualmente
            completed_with_values = [(t, t.value) for t in completed_trials if t.value is not None]
            completed_with_values.sort(key=lambda x: x[1], reverse=True)
            top_trials = [t[0] for t in completed_with_values[:top_n]]
            analysis_type = "COMPLETADOS"
    
    print(f"   Analisando top {len(top_trials)} trials {analysis_type}...")
    
    # Criar arquivo de saÃ­da
    with open(output_path, 'w', encoding='utf-8') as f:
        # CabeÃ§alho
        f.write("="*80 + "\n")
        f.write(f"ANÃLISE DOS TOP {len(top_trials)} TRIALS DO OPTUNA\n")
        f.write("="*80 + "\n\n")

        f.write(f"Study: {Path(study.study_name).name if hasattr(study, 'study_name') else 'N/A'}\n")
        f.write(f"Total de trials: {len(study.trials)}\n")
        f.write(f"Trials completados: {len(completed_trials)}\n")
        f.write(f"Trials pruned: {len(pruned_trials)}\n")
        f.write(f"Tipo de anÃ¡lise: {analysis_type}\n")
        f.write(f"\n{'='*80}\n\n")
        
        # Analisar cada trial
        for rank, trial in enumerate(top_trials, 1):
            summary = get_trial_metrics_summary(trial)
            
            f.write(f"\n{'='*80}\n")
            f.write(f"RANK #{rank} - TRIAL {summary['trial_number']}\n")
            f.write(f"{'='*80}\n\n")
            
            # Status do trial
            f.write(f"Status: {summary['state']}\n")
            if summary['value'] is not None:
                if summary['state'] == 'COMPLETE':
                    f.write(f"F1-score mÃ©dio (todos os folds): {summary['value']:.4f}\n")
                else:
                    f.write(f"F1-score (Fold 1 apenas): {summary['value']:.4f}\n")
                    if 'pruned_reason' in summary:
                        f.write(f"RazÃ£o do pruning: {summary['pruned_reason']}\n")
            
            # HiperparÃ¢metros
            f.write(f"\n{'-'*80}\n")
            f.write("HIPERPARÃ‚METROS\n")
            f.write(f"{'-'*80}\n\n")
            for key, value in summary['params'].items():
                f.write(f"  {key}: {value}\n")
            
            # MÃ©tricas por fold
            if summary['fold_metrics']:
                f.write(f"\n{'-'*80}\n")
                f.write("MÃ‰TRICAS POR FOLD\n")
                f.write(f"{'-'*80}\n")
                
                for fold_data in summary['fold_metrics']:
                    if isinstance(fold_data, dict):
                        fold_num = fold_data.get('fold', 1)
                        f.write(f"\n  ğŸ“ FOLD {fold_num}\n")
                        f.write(f"  {'='*96}\n")
                        
                        # Melhor Ã©poca e Ãºltima Ã©poca
                        if 'best_epoch' in fold_data:
                            f.write(f"  Melhor Ã©poca: {fold_data['best_epoch']}\n")
                        
                        # Tentar obter Ãºltima Ã©poca do histÃ³rico
                        if 'history' in fold_data and 'epochs' in fold_data['history']:
                            last_epoch = fold_data['history']['epochs'][-1] if fold_data['history']['epochs'] else 'N/A'
                            f.write(f"  Ãšltima Ã©poca executada: {last_epoch}\n")
                        
                        f.write("\n")
                        
                        # MÃ©tricas de validaÃ§Ã£o
                        if 'val_metrics' in fold_data:
                            val_metrics = fold_data['val_metrics']
                            f.write(f"  ğŸ”¹ MÃ‰TRICAS DE VALIDAÃ‡ÃƒO (GLOBAIS):\n")
                            f.write(format_global_metrics(val_metrics, indent='    '))
                            f.write("\n\n")
                            
                            f.write(f"  ğŸ”¹ MÃ‰TRICAS DE VALIDAÃ‡ÃƒO (POR CLASSE):\n")
                            per_class = format_metrics_per_class(val_metrics, indent='    ')
                            if per_class:
                                f.write(per_class)
                            else:
                                f.write("    MÃ©tricas por classe nÃ£o disponÃ­veis\n")
                            f.write("\n\n")
                        
                        # MÃ©tricas de treino
                        if 'train_metrics' in fold_data:
                            train_metrics = fold_data['train_metrics']
                            f.write(f"  ğŸ”¹ MÃ‰TRICAS DE TREINO (GLOBAIS):\n")
                            f.write(format_global_metrics(train_metrics, indent='    '))
                            f.write("\n\n")
                            
                            f.write(f"  ğŸ”¹ MÃ‰TRICAS DE TREINO (POR CLASSE):\n")
                            per_class = format_metrics_per_class(train_metrics, indent='    ')
                            if per_class:
                                f.write(per_class)
                            else:
                                f.write("    MÃ©tricas por classe nÃ£o disponÃ­veis\n")
                            f.write("\n")
            else:
                f.write(f"\n{'-'*80}\n")
                f.write("âš ï¸ MÃ©tricas detalhadas nÃ£o disponÃ­veis para este trial\n")
                f.write(f"{'-'*80}\n")
            
            f.write("\n" + "="*80 + "\n")

        # Resumo comparativo
        f.write(f"\n\n{'='*80}\n")
        f.write("RESUMO COMPARATIVO DOS TOP TRIALS\n")
        f.write(f"{'='*80}\n\n")

        # Tabela ASCII para resumo
        f.write("â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n")
        f.write("â”‚ Rank â”‚  Trial  â”‚  F1-Score  â”‚    Status    â”‚    Head Type    â”‚    Block Type    â”‚\n")
        f.write("â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n")
        
        for rank, trial in enumerate(top_trials, 1):
            summary = get_trial_metrics_summary(trial)
            f1_str = f"{summary['value']:.4f}" if summary['value'] is not None else "  N/A   "
            head_type = summary['params'].get('head_type', 'N/A')
            block_type = summary['params'].get('block_type', 'N/A')
            
            # Truncar strings longas
            head_type_str = head_type[:15].ljust(15)
            block_type_str = block_type[:16].ljust(16)
            
            f.write(f"â”‚  #{rank}  â”‚  {summary['trial_number']:5}  â”‚  {f1_str}  â”‚ {summary['state']:12} â”‚ {head_type_str}â”‚ {block_type_str}â”‚\n")
        
        f.write("â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n")

        f.write("\n" + "="*80 + "\n")
        f.write("FIM DA ANÃLISE\n")
        f.write("="*80 + "\n")

    print(f"\nâœ… AnÃ¡lise salva em: {output_path}")
    print(f"   Total de trials analisados: {len(top_trials)}")
    
    # Gerar grÃ¡ficos se solicitado
    if generate_plots:
        if not os.path.exists(plots_dir):
            os.makedirs(plots_dir)
            print(f"\nğŸ“ DiretÃ³rio de plots criado: {plots_dir}")
        
        print(f"\nğŸ“Š Gerando grÃ¡ficos de treinamento...")
        generated_plots = 0
        
        for rank, trial in enumerate(top_trials, 1):
            summary = get_trial_metrics_summary(trial)
            print(f"\n  ğŸ”„ Processando Trial {summary['trial_number']} (Rank #{rank})...")
            
            result = generate_trial_plots(summary, rank, plots_dir)
            if result:
                generated_plots += 1
        
        print(f"\nâœ… Total de grÃ¡ficos gerados: {generated_plots}")
    
    return top_trials


def main():
    """FunÃ§Ã£o principal"""
    args = parse_args()
    
    print("="*80)
    print("ANALISADOR DE TRIALS DO OPTUNA")
    print("="*80)
    print(f"\nConfiguraÃ§Ã£o:")
    print(f"  Study path: {args.study_path}")
    print(f"  Output file: {args.output}")
    print(f"  Top N trials: {args.top_n}")
    print(f"  Incluir pruned: {'Sim' if args.include_pruned else 'NÃ£o'}")
    print(f"  Gerar grÃ¡ficos: {'Sim' if args.generate_plots else 'NÃ£o'}")
    if args.generate_plots:
        print(f"  DiretÃ³rio dos grÃ¡ficos: {args.plots_dir}")
    
    # Carregar study
    study = load_optuna_study(args.study_path)
    if study is None:
        print("\nâŒ NÃ£o foi possÃ­vel carregar o study. Abortando...")
        return
    
    # Analisar e salvar
    analyze_and_save(
        study, 
        args.output, 
        args.top_n, 
        args.include_pruned,
        generate_plots=args.generate_plots,
        plots_dir=args.plots_dir
    )
    
    print("\n" + "="*80)
    print("âœ… ANÃLISE CONCLUÃDA COM SUCESSO!")
    print("="*80)


if __name__ == '__main__':
    main()
