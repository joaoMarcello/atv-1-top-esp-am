{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFZkCZrIHNzz"
      },
      "outputs": [],
      "source": [
        "#1ï¸âƒ£ Instalar as bibliotecas\n",
        "!pip install torch torchvision torchaudio optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2ï¸âƒ£ Verificar se o PyTorch detecta GPU\n",
        "#Execute:\n",
        "import torch\n",
        "\n",
        "print(\"VersÃ£o do PyTorch:\", torch.__version__)\n",
        "print(\"CUDA disponÃ­vel:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Nome da GPU:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "Wx-ALtuCOLb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estrutura do projeto\n",
        "\n",
        "#O notebook final serÃ¡ dividido em:\n",
        "\n",
        "#InstalaÃ§Ã£o de bibliotecas e imports\n",
        "\n",
        "#Upload e configuraÃ§Ã£o do dataset (EyePACS ou similar)\n",
        "\n",
        "#DefiniÃ§Ã£o do modelo (AnyNet + CORAL + OLR)\n",
        "\n",
        "#FunÃ§Ãµes de treino, validaÃ§Ã£o e mÃ©tricas\n",
        "\n",
        "#ConfiguraÃ§Ã£o do Optuna (TPE)\n",
        "\n",
        "#Treinamento e salvamento do melhor modelo"
      ],
      "metadata": {
        "id": "zoKbKe82ODVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ğŸ”§ 1. InstalaÃ§Ã£o e imports\n",
        "# ============================================\n",
        "\n",
        "!pip install optuna albumentations timm --quiet\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "import timm\n",
        "import optuna\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Usando dispositivo:\", DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoBBBGIiHe5i",
        "outputId": "5241dd86-4fd4-432c-d7c9-bd9df208eaa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/400.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m225.3/400.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsando dispositivo: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ğŸ“‚ 2. Dataset e DataLoader\n",
        "# ============================================\n",
        "\n",
        "# Estrutura esperada:\n",
        "# /content/eyepacs/\n",
        "# â”œâ”€â”€ train_images/\n",
        "# â”‚      â”œâ”€â”€ 0001.png\n",
        "# â”‚      â”œâ”€â”€ 0002.png\n",
        "# â”‚      â””â”€â”€ ...\n",
        "# â”œâ”€â”€ labels.csv  (colunas: image_id,label)\n",
        "\n",
        "DATA_DIR = \"/content/sample_data\"\n",
        "CSV_PATH = os.path.join(DATA_DIR, \"labels.csv\")\n",
        "\n",
        "# Se vocÃª ainda nÃ£o tem, crie e envie:\n",
        "# !mkdir -p /content/eyepacs/train_images\n",
        "# depois use o painel lateral do Colab â†’ \"Arquivos\" â†’ \"Upload\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(\"Amostras:\", len(df))\n",
        "print(df.head())\n",
        "\n",
        "# Split treino/val\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
        "\n",
        "class EyeDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        path = os.path.join(self.img_dir, str(row['image_id']) + \".png\")\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "            img = self.transform(image=img)[\"image\"]\n",
        "        label = torch.tensor(row['label']).long()\n",
        "        return img, label\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "def get_transforms(train=True):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.Resize(320, 320),\n",
        "            A.HorizontalFlip(),\n",
        "            A.Rotate(limit=25),\n",
        "            A.RandomBrightnessContrast(),\n",
        "            A.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                        std=(0.229, 0.224, 0.225)),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(320, 320),\n",
        "            A.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                        std=(0.229, 0.224, 0.225)),\n",
        "            ToTensorV2(),\n",
        "        ])\n"
      ],
      "metadata": {
        "id": "vQTPnGJ8Hu9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ğŸ§© 3. Modelo AnyNet + CORAL + OLR\n",
        "# ============================================\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, c, reduction=16):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(c, c // reduction)\n",
        "        self.fc2 = nn.Linear(c // reduction, c)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = F.adaptive_avg_pool2d(x, 1).view(b, c)\n",
        "        y = F.relu(self.fc1(y))\n",
        "        y = torch.sigmoid(self.fc2(y)).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "class ResNeXtBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c, stride=1, cardinality=8, use_se=True):\n",
        "        super().__init__()\n",
        "        mid_c = out_c // 2\n",
        "        self.conv1 = nn.Conv2d(in_c, mid_c, kernel_size=1, bias=False)\n",
        "        self.conv2 = nn.Conv2d(mid_c, mid_c, kernel_size=3,\n",
        "                               stride=stride, padding=1, groups=cardinality, bias=False)\n",
        "        self.conv3 = nn.Conv2d(mid_c, out_c, kernel_size=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_c)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_c != out_c:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_c, out_c, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_c)\n",
        "            )\n",
        "        self.use_se = use_se\n",
        "        if use_se:\n",
        "            self.se = SEBlock(out_c)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = self.conv3(out)\n",
        "        if self.use_se:\n",
        "            out = self.se(out)\n",
        "        out += self.shortcut(x)\n",
        "        return F.relu(self.bn(out))\n",
        "\n",
        "# ---- HEADS ---- #\n",
        "\n",
        "class CoralHead(nn.Module):\n",
        "    \"\"\"Head para classificaÃ§Ã£o ordinal CORAL\"\"\"\n",
        "    def __init__(self, in_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.fc = nn.Linear(in_features, 1)\n",
        "        self.register_parameter(\"bias\", nn.Parameter(torch.zeros(num_classes - 1)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        logit = self.fc(x).squeeze(-1)\n",
        "        logits = logit.unsqueeze(1) - self.bias.unsqueeze(0)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        return probs\n",
        "\n",
        "def coral_loss(probs, targets):\n",
        "    Kminus1 = probs.size(1)\n",
        "    cum_targets = (torch.arange(Kminus1).to(targets.device).unsqueeze(0) < targets.unsqueeze(1)).float()\n",
        "    return F.binary_cross_entropy(probs, cum_targets, reduction='mean')\n",
        "\n",
        "class OrdinalLogisticHead(nn.Module):\n",
        "    \"\"\"Head de RegressÃ£o LogÃ­stica Ordinal (OLR)\"\"\"\n",
        "    def __init__(self, in_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.fc = nn.Linear(in_features, 1)\n",
        "        # thresholds (cortes)\n",
        "        self.theta = nn.Parameter(torch.arange(num_classes - 1).float())\n",
        "\n",
        "    def forward(self, x):\n",
        "        # retorna probabilidades cumulativas P(y > k)\n",
        "        eta = self.fc(x)\n",
        "        logits = eta - self.theta\n",
        "        probs = torch.sigmoid(logits)\n",
        "        return probs\n",
        "\n",
        "def olr_loss(probs, targets):\n",
        "    Kminus1 = probs.size(1)\n",
        "    # y > k cumulativo\n",
        "    cum_targets = (torch.arange(Kminus1).to(targets.device).unsqueeze(0) < targets.unsqueeze(1)).float()\n",
        "    loss = F.binary_cross_entropy(probs, cum_targets, reduction='mean')\n",
        "    return loss\n",
        "\n",
        "# ---- Modelo AnyNet ---- #\n",
        "\n",
        "class AnyNet(nn.Module):\n",
        "    def __init__(self, num_classes=5, use_se=True, head_type=\"coral\"):\n",
        "        super().__init__()\n",
        "        self.head_type = head_type\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.LayerNorm([32, 160, 160]),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.stage1 = ResNeXtBlock(32, 64, stride=1, use_se=use_se)\n",
        "        self.stage2 = ResNeXtBlock(64, 128, stride=2, use_se=use_se)\n",
        "        self.stage3 = ResNeXtBlock(128, 256, stride=2, use_se=use_se)\n",
        "        self.stage4 = ResNeXtBlock(256, 512, stride=2, use_se=use_se)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        if head_type == \"coral\":\n",
        "            self.head = CoralHead(512, num_classes)\n",
        "        else:\n",
        "            self.head = OrdinalLogisticHead(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = self.pool(x).flatten(1)\n",
        "        return self.head(x)\n"
      ],
      "metadata": {
        "id": "xMdQDYjGNPFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# âš™ï¸ 4. FunÃ§Ãµes de treino e validaÃ§Ã£o\n",
        "# ============================================\n",
        "\n",
        "def ordinal_predict(probs):\n",
        "    return torch.sum(probs > 0.5, dim=1)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for imgs, labels in loader:\n",
        "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        probs = model(imgs)\n",
        "        loss = criterion(probs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def validate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "            probs = model(imgs)\n",
        "            loss = criterion(probs, labels)\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            pred = ordinal_predict(probs)\n",
        "            preds.extend(pred.cpu().numpy())\n",
        "            trues.extend(labels.cpu().numpy())\n",
        "    qwk = cohen_kappa_score(trues, preds, weights='quadratic')\n",
        "    return total_loss / len(loader.dataset), qwk\n"
      ],
      "metadata": {
        "id": "45S1NpwQNWyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ğŸ§ª 5. OtimizaÃ§Ã£o com Optuna (TPE)\n",
        "# ============================================\n",
        "\n",
        "def objective(trial):\n",
        "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
        "    wd = trial.suggest_loguniform(\"wd\", 1e-6, 1e-3)\n",
        "    use_se = trial.suggest_categorical(\"use_se\", [True, False])\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    head_type = trial.suggest_categorical(\"head_type\", [\"coral\", \"olr\"])\n",
        "\n",
        "    model = AnyNet(num_classes=5, use_se=use_se, head_type=head_type).to(DEVICE)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    criterion = coral_loss if head_type == \"coral\" else olr_loss\n",
        "\n",
        "    train_set = EyeDataset(train_df, os.path.join(DATA_DIR, \"train_images\"), transform=get_transforms(True))\n",
        "    val_set = EyeDataset(val_df, os.path.join(DATA_DIR, \"train_images\"), transform=get_transforms(False))\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    best_qwk = -1\n",
        "    patience, bad_epochs = 5, 0\n",
        "    for epoch in range(15):\n",
        "        tr_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "        val_loss, qwk = validate(model, val_loader, criterion)\n",
        "        trial.report(qwk, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "        if qwk > best_qwk:\n",
        "            best_qwk = qwk\n",
        "            bad_epochs = 0\n",
        "        else:\n",
        "            bad_epochs += 1\n",
        "            if bad_epochs >= patience:\n",
        "                break\n",
        "    return best_qwk\n"
      ],
      "metadata": {
        "id": "2toqjZr1NaaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ğŸ¯ 6. Rodar o Optuna e treinar o melhor modelo\n",
        "# ============================================\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(objective, n_trials=10)  # aumente para 50â€“200 se tiver GPU\n",
        "\n",
        "print(\"Melhores parÃ¢metros:\", study.best_params)\n",
        "print(\"Melhor QWK:\", study.best_value)\n",
        "\n",
        "best_params = study.best_params\n",
        "model = AnyNet(num_classes=5, use_se=best_params['use_se'], head_type=best_params['head_type']).to(DEVICE)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=best_params['lr'], weight_decay=best_params['wd'])\n",
        "criterion = coral_loss if best_params['head_type'] == \"coral\" else olr_loss\n",
        "\n",
        "train_set = EyeDataset(train_df, os.path.join(DATA_DIR, \"train_images\"), transform=get_transforms(True))\n",
        "val_set = EyeDataset(val_df, os.path.join(DATA_DIR, \"train_images\"), transform=get_transforms(False))\n",
        "train_loader = DataLoader(train_set, batch_size=best_params['batch_size'], shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_set, batch_size=best_params['batch_size'], shuffle=False, num_workers=2)\n",
        "\n",
        "best_qwk = -1\n",
        "for epoch in range(25):\n",
        "    tr_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, qwk = validate(model, val_loader, criterion)\n",
        "    print(f\"Epoch {epoch+1}: Train {tr_loss:.4f} | Val {val_loss:.4f} | QWK {qwk:.4f}\")\n",
        "    if qwk > best_qwk:\n",
        "        best_qwk = qwk\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "print(\"Treinamento finalizado. Melhor QWK:\", best_qwk)\n",
        "print(\"Modelo salvo como best_model.pth\")\n"
      ],
      "metadata": {
        "id": "s5tdsVIcNePw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}