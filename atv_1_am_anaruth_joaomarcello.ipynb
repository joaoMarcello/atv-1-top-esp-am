{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFZkCZrIHNzz"
      },
      "outputs": [],
      "source": [
        "#1️⃣ Instalar as bibliotecas\n",
        "!pip install torch torchvision torchaudio optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2️⃣ Verificar se o PyTorch detecta GPU\n",
        "#Execute:\n",
        "import torch\n",
        "\n",
        "print(\"Versão do PyTorch:\", torch.__version__)\n",
        "print(\"CUDA disponível:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Nome da GPU:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "Wx-ALtuCOLb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estrutura do projeto\n",
        "\n",
        "#O notebook final será dividido em:\n",
        "\n",
        "#Instalação de bibliotecas e imports\n",
        "\n",
        "#Upload e configuração do dataset (EyePACS ou similar)\n",
        "\n",
        "#Definição do modelo (AnyNet + CORAL + OLR)\n",
        "\n",
        "#Funções de treino, validação e métricas\n",
        "\n",
        "#Configuração do Optuna (TPE)\n",
        "\n",
        "#Treinamento e salvamento do melhor modelo"
      ],
      "metadata": {
        "id": "zoKbKe82ODVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 🔧 1. Instalação e imports\n",
        "# ============================================\n",
        "\n",
        "!pip install optuna albumentations timm --quiet\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "import timm\n",
        "import optuna\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Usando dispositivo:\", DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoBBBGIiHe5i",
        "outputId": "5241dd86-4fd4-432c-d7c9-bd9df208eaa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/400.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/400.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsando dispositivo: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 📂 2. Dataset e DataLoader\n",
        "# ============================================\n",
        "\n",
        "# Estrutura esperada:\n",
        "# /content/eyepacs/\n",
        "# ├── train_images/\n",
        "# │      ├── 0001.png\n",
        "# │      ├── 0002.png\n",
        "# │      └── ...\n",
        "# ├── labels.csv  (colunas: image_id,label)\n",
        "\n",
        "DATA_DIR = \"/content/sample_data\"\n",
        "CSV_PATH = os.path.join(DATA_DIR, \"labels.csv\")\n",
        "\n",
        "# Se você ainda não tem, crie e envie:\n",
        "# !mkdir -p /content/eyepacs/train_images\n",
        "# depois use o painel lateral do Colab → \"Arquivos\" → \"Upload\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(\"Amostras:\", len(df))\n",
        "print(df.head())\n",
        "\n",
        "# Split treino/val\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
        "\n",
        "class EyeDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        path = os.path.join(self.img_dir, str(row['image_id']) + \".png\")\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "            img = self.transform(image=img)[\"image\"]\n",
        "        label = torch.tensor(row['label']).long()\n",
        "        return img, label\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "def get_transforms(train=True):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.Resize(320, 320),\n",
        "            A.HorizontalFlip(),\n",
        "            A.Rotate(limit=25),\n",
        "            A.RandomBrightnessContrast(),\n",
        "            A.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                        std=(0.229, 0.224, 0.225)),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(320, 320),\n",
        "            A.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                        std=(0.229, 0.224, 0.225)),\n",
        "            ToTensorV2(),\n",
        "        ])\n"
      ],
      "metadata": {
        "id": "vQTPnGJ8Hu9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 🧩 3. Modelo AnyNet + CORAL + OLR\n",
        "# ============================================\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, c, reduction=16):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(c, c // reduction)\n",
        "        self.fc2 = nn.Linear(c // reduction, c)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = F.adaptive_avg_pool2d(x, 1).view(b, c)\n",
        "        y = F.relu(self.fc1(y))\n",
        "        y = torch.sigmoid(self.fc2(y)).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "class ResNeXtBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c, stride=1, cardinality=8, use_se=True):\n",
        "        super().__init__()\n",
        "        mid_c = out_c // 2\n",
        "        self.conv1 = nn.Conv2d(in_c, mid_c, kernel_size=1, bias=False)\n",
        "        self.conv2 = nn.Conv2d(mid_c, mid_c, kernel_size=3,\n",
        "                               stride=stride, padding=1, groups=cardinality, bias=False)\n",
        "        self.conv3 = nn.Conv2d(mid_c, out_c, kernel_size=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_c)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_c != out_c:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_c, out_c, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_c)\n",
        "            )\n",
        "        self.use_se = use_se\n",
        "        if use_se:\n",
        "            self.se = SEBlock(out_c)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = self.conv3(out)\n",
        "        if self.use_se:\n",
        "            out = self.se(out)\n",
        "        out += self.shortcut(x)\n",
        "        return F.relu(self.bn(out))\n",
        "\n",
        "# ---- HEADS ---- #\n",
        "\n",
        "class CoralHead(nn.Module):\n",
        "    \"\"\"Head para classificação ordinal CORAL\"\"\"\n",
        "    def __init__(self, in_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.fc = nn.Linear(in_features, 1)\n",
        "        self.register_parameter(\"bias\", nn.Parameter(torch.zeros(num_classes - 1)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        logit = self.fc(x).squeeze(-1)\n",
        "        logits = logit.unsqueeze(1) - self.bias.unsqueeze(0)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        return probs\n",
        "\n",
        "def coral_loss(probs, targets):\n",
        "    Kminus1 = probs.size(1)\n",
        "    cum_targets = (torch.arange(Kminus1).to(targets.device).unsqueeze(0) < targets.unsqueeze(1)).float()\n",
        "    return F.binary_cross_entropy(probs, cum_targets, reduction='mean')\n",
        "\n",
        "class OrdinalLogisticHead(nn.Module):\n",
        "    \"\"\"Head de Regressão Logística Ordinal (OLR)\"\"\"\n",
        "    def __init__(self, in_features, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.fc = nn.Linear(in_features, 1)\n",
        "        # thresholds (cortes)\n",
        "        self.theta = nn.Parameter(torch.arange(num_classes - 1).float())\n",
        "\n",
        "    def forward(self, x):\n",
        "        # retorna probabilidades cumulativas P(y > k)\n",
        "        eta = self.fc(x)\n",
        "        logits = eta - self.theta\n",
        "        probs = torch.sigmoid(logits)\n",
        "        return probs\n",
        "\n",
        "def olr_loss(probs, targets):\n",
        "    Kminus1 = probs.size(1)\n",
        "    # y > k cumulativo\n",
        "    cum_targets = (torch.arange(Kminus1).to(targets.device).unsqueeze(0) < targets.unsqueeze(1)).float()\n",
        "    loss = F.binary_cross_entropy(probs, cum_targets, reduction='mean')\n",
        "    return loss\n",
        "\n",
        "# ---- Modelo AnyNet ---- #\n",
        "\n",
        "class AnyNet(nn.Module):\n",
        "    def __init__(self, num_classes=5, use_se=True, head_type=\"coral\"):\n",
        "        super().__init__()\n",
        "        self.head_type = head_type\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.LayerNorm([32, 160, 160]),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.stage1 = ResNeXtBlock(32, 64, stride=1, use_se=use_se)\n",
        "        self.stage2 = ResNeXtBlock(64, 128, stride=2, use_se=use_se)\n",
        "        self.stage3 = ResNeXtBlock(128, 256, stride=2, use_se=use_se)\n",
        "        self.stage4 = ResNeXtBlock(256, 512, stride=2, use_se=use_se)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        if head_type == \"coral\":\n",
        "            self.head = CoralHead(512, num_classes)\n",
        "        else:\n",
        "            self.head = OrdinalLogisticHead(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = self.pool(x).flatten(1)\n",
        "        return self.head(x)\n"
      ],
      "metadata": {
        "id": "xMdQDYjGNPFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ⚙️ 4. Funções de treino e validação\n",
        "# ============================================\n",
        "\n",
        "def ordinal_predict(probs):\n",
        "    return torch.sum(probs > 0.5, dim=1)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for imgs, labels in loader:\n",
        "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        probs = model(imgs)\n",
        "        loss = criterion(probs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def validate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "            probs = model(imgs)\n",
        "            loss = criterion(probs, labels)\n",
        "            total_loss += loss.item() * imgs.size(0)\n",
        "            pred = ordinal_predict(probs)\n",
        "            preds.extend(pred.cpu().numpy())\n",
        "            trues.extend(labels.cpu().numpy())\n",
        "    qwk = cohen_kappa_score(trues, preds, weights='quadratic')\n",
        "    return total_loss / len(loader.dataset), qwk\n"
      ],
      "metadata": {
        "id": "45S1NpwQNWyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 🧪 5. Otimização com Optuna (TPE)\n",
        "# ============================================\n",
        "\n",
        "def objective(trial):\n",
        "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
        "    wd = trial.suggest_loguniform(\"wd\", 1e-6, 1e-3)\n",
        "    use_se = trial.suggest_categorical(\"use_se\", [True, False])\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    head_type = trial.suggest_categorical(\"head_type\", [\"coral\", \"olr\"])\n",
        "\n",
        "    model = AnyNet(num_classes=5, use_se=use_se, head_type=head_type).to(DEVICE)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    criterion = coral_loss if head_type == \"coral\" else olr_loss\n",
        "\n",
        "    train_set = EyeDataset(train_df, os.path.join(DATA_DIR, \"train_images\"), transform=get_transforms(True))\n",
        "    val_set = EyeDataset(val_df, os.path.join(DATA_DIR, \"train_images\"), transform=get_transforms(False))\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    best_qwk = -1\n",
        "    patience, bad_epochs = 5, 0\n",
        "    for epoch in range(15):\n",
        "        tr_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "        val_loss, qwk = validate(model, val_loader, criterion)\n",
        "        trial.report(qwk, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "        if qwk > best_qwk:\n",
        "            best_qwk = qwk\n",
        "            bad_epochs = 0\n",
        "        else:\n",
        "            bad_epochs += 1\n",
        "            if bad_epochs >= patience:\n",
        "                break\n",
        "    return best_qwk\n"
      ],
      "metadata": {
        "id": "2toqjZr1NaaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 🎯 6. Rodar o Optuna e treinar o melhor modelo\n",
        "# ============================================\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(objective, n_trials=10)  # aumente para 50–200 se tiver GPU\n",
        "\n",
        "print(\"Melhores parâmetros:\", study.best_params)\n",
        "print(\"Melhor QWK:\", study.best_value)\n",
        "\n",
        "best_params = study.best_params\n",
        "model = AnyNet(num_classes=5, use_se=best_params['use_se'], head_type=best_params['head_type']).to(DEVICE)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=best_params['lr'], weight_decay=best_params['wd'])\n",
        "criterion = coral_loss if best_params['head_type'] == \"coral\" else olr_loss\n",
        "\n",
        "train_set = EyeDataset(train_df, os.path.join(DATA_DIR, \"train_images\"), transform=get_transforms(True))\n",
        "val_set = EyeDataset(val_df, os.path.join(DATA_DIR, \"train_images\"), transform=get_transforms(False))\n",
        "train_loader = DataLoader(train_set, batch_size=best_params['batch_size'], shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_set, batch_size=best_params['batch_size'], shuffle=False, num_workers=2)\n",
        "\n",
        "best_qwk = -1\n",
        "for epoch in range(25):\n",
        "    tr_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, qwk = validate(model, val_loader, criterion)\n",
        "    print(f\"Epoch {epoch+1}: Train {tr_loss:.4f} | Val {val_loss:.4f} | QWK {qwk:.4f}\")\n",
        "    if qwk > best_qwk:\n",
        "        best_qwk = qwk\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "print(\"Treinamento finalizado. Melhor QWK:\", best_qwk)\n",
        "print(\"Modelo salvo como best_model.pth\")\n"
      ],
      "metadata": {
        "id": "s5tdsVIcNePw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}